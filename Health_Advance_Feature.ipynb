{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d00114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures # For creating polynomial features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d36bc48",
   "metadata": {},
   "source": [
    "# --- 1. Load the Dataset ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1648549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "      <th>cp_0</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>cp_2</th>\n",
       "      <th>cp_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0     52    1       125   212    0        1      168      0      1.0      2   \n",
       "1     53    1       140   203    1        0      155      1      3.1      0   \n",
       "2     70    1       145   174    0        1      125      1      2.6      0   \n",
       "3     61    1       148   203    0        1      161      0      0.0      2   \n",
       "4     62    0       138   294    1        1      106      0      1.9      1   \n",
       "..   ...  ...       ...   ...  ...      ...      ...    ...      ...    ...   \n",
       "297   68    0       120   211    0        0      115      0      1.5      1   \n",
       "298   44    0       108   141    0        1      175      0      0.6      1   \n",
       "299   52    1       128   255    0        1      161      1      0.0      2   \n",
       "300   59    1       160   273    0        0      125      0      0.0      2   \n",
       "301   54    1       120   188    0        1      113      0      1.4      1   \n",
       "\n",
       "     ca  thal  target  cp_0  cp_1  cp_2  cp_3  \n",
       "0     2     3       0     1     0     0     0  \n",
       "1     0     3       0     1     0     0     0  \n",
       "2     0     3       0     1     0     0     0  \n",
       "3     1     3       0     1     0     0     0  \n",
       "4     3     2       0     1     0     0     0  \n",
       "..   ..   ...     ...   ...   ...   ...   ...  \n",
       "297   0     2       1     0     0     1     0  \n",
       "298   0     2       1     0     0     1     0  \n",
       "299   1     3       0     1     0     0     0  \n",
       "300   0     2       0     0     0     0     1  \n",
       "301   1     3       0     1     0     0     0  \n",
       "\n",
       "[302 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data that is inside of the CSV\n",
    "df = pd.read_csv(\"./Health_Data/cleaned_health.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "929eb18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define original features and target columns\n",
    "ORIGINAL_FEATURES = [\n",
    "    'age', 'sex', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
    "    'exang', 'oldpeak', 'slope', 'ca', 'thal',\n",
    "    'cp_0', 'cp_1', 'cp_2', 'cp_3'\n",
    "]\n",
    "TARGET_COL = 'target' # The column indicating disease presence (0 or 1)\n",
    "\n",
    "# Define numerical columns for imputation and potential engineering\n",
    "NUMERICAL_COLS_FOR_PROCESSING = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a47d2b",
   "metadata": {},
   "source": [
    "# --- 2. Data Preprocessing (Ensuring Cleanliness and Correct Types) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abb0d8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Preprocessing for Feature Engineering ---\n",
      "Missing values before imputation:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Missing values after imputation:\n",
      "age         0\n",
      "sex         0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "cp_0        0\n",
      "cp_1        0\n",
      "cp_2        0\n",
      "cp_3        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Data Preprocessing for Feature Engineering ---\")\n",
    "\n",
    "# Handle '?' or other non-numeric values if they exist, converting to NaN first\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.replace('N/A', np.nan, inplace=True)\n",
    "\n",
    "# Convert all relevant columns to numeric, coercing errors\n",
    "all_relevant_cols = ORIGINAL_FEATURES + [TARGET_COL]\n",
    "for col in all_relevant_cols:\n",
    "    if col in df.columns:\n",
    "        if col in NUMERICAL_COLS_FOR_PROCESSING:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        else: # Categorical/binary features including target\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64') # Use nullable integer\n",
    "\n",
    "# Impute missing values after type conversion\n",
    "print(\"Missing values before imputation:\")\n",
    "print(df[all_relevant_cols].isnull().sum()[df[all_relevant_cols].isnull().sum() > 0])\n",
    "\n",
    "for col in all_relevant_cols:\n",
    "    if col in df.columns and df[col].isnull().any():\n",
    "        if col in NUMERICAL_COLS_FOR_PROCESSING:\n",
    "            median_val = df[col].median()\n",
    "            df[col].fillna(median_val, inplace=True)\n",
    "            print(f\"Filled missing values in '{col}' with its median ({median_val}).\")\n",
    "        else: # Categorical/binary features including target\n",
    "            mode_val = df[col].mode()[0]\n",
    "            df[col].fillna(mode_val, inplace=True)\n",
    "            print(f\"Filled missing values in '{col}' with its mode ({mode_val}).\")\n",
    "\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(df[all_relevant_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de13704",
   "metadata": {},
   "source": [
    "# --- 3. Advanced Feature Engineering ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dbbf103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing Advanced Feature Engineering ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Performing Advanced Feature Engineering ---\")\n",
    "\n",
    "# Create a copy of the DataFrame to add new features\n",
    "df_engineered = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae8a17",
   "metadata": {},
   "source": [
    "# --- 3.1. Polynomial Features ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fd6d402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added polynomial features for: ['age', 'trestbps', 'chol']\n",
      "New polynomial features created: ['age' 'trestbps' 'chol' 'age^2' 'age trestbps' 'age chol' 'trestbps^2'\n",
      " 'trestbps chol' 'chol^2']\n"
     ]
    }
   ],
   "source": [
    "# Create polynomial features for selected numerical columns\n",
    "# degree=2 means it will create feature^2 and interaction terms (feature1 * feature2)\n",
    "# include_bias=False ensures it doesn't add a column of all ones\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "cols_for_poly = ['age', 'trestbps', 'chol'] # Select features to create polynomials from\n",
    "\n",
    "# Ensure selected columns exist before processing\n",
    "actual_cols_for_poly = [col for col in cols_for_poly if col in df_engineered.columns]\n",
    "\n",
    "if actual_cols_for_poly:\n",
    "    # Fit and transform the selected columns\n",
    "    poly_features = poly.fit_transform(df_engineered[actual_cols_for_poly])\n",
    "    # Get the names of the new polynomial features\n",
    "    poly_feature_names = poly.get_feature_names_out(actual_cols_for_poly)\n",
    "    # Create a DataFrame for the new polynomial features\n",
    "    poly_df = pd.DataFrame(poly_features, columns=poly_feature_names, index=df_engineered.index)\n",
    "    # Concatenate the new polynomial features to the main DataFrame\n",
    "    df_engineered = pd.concat([df_engineered, poly_df], axis=1)\n",
    "    print(f\"Added polynomial features for: {actual_cols_for_poly}\")\n",
    "    print(f\"New polynomial features created: {poly_feature_names}\")\n",
    "else:\n",
    "    print(\"Skipping polynomial features: None of the specified columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37478250",
   "metadata": {},
   "source": [
    "# --- 3.2. Interaction Features (Manual) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24daa351",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column age_x_chol",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12092\\1946973887.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create specific interaction terms that might be clinically relevant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Ensure both interacting columns exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'age'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_engineered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'chol'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_engineered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf_engineered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'age_x_chol'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_engineered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdf_engineered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'chol'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Added interaction feature: 'age_x_chol'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Skipping interaction feature 'age_x_chol': One or both columns not found.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lualg\\anaconda3\\envs\\streamlit_pycaret\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3966\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3967\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3968\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m         elif (\n\u001b[0;32m   3972\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3973\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lualg\\anaconda3\\envs\\streamlit_pycaret\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4121\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4122\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4125\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   4126\u001b[0m                 \u001b[1;34m\"Cannot set a DataFrame with multiple columns to the single \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4127\u001b[0m                 \u001b[1;34mf\"column {key}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4128\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set a DataFrame with multiple columns to the single column age_x_chol"
     ]
    }
   ],
   "source": [
    "# Create specific interaction terms that might be clinically relevant\n",
    "# Ensure both interacting columns exist\n",
    "if 'age' in df_engineered.columns and 'chol' in df_engineered.columns:\n",
    "    df_engineered['age_x_chol'] = df_engineered['age'] * df_engineered['chol']\n",
    "    print(\"Added interaction feature: 'age_x_chol'\")\n",
    "else:\n",
    "    print(\"Skipping interaction feature 'age_x_chol': One or both columns not found.\")\n",
    "\n",
    "if 'thalach' in df_engineered.columns and 'exang' in df_engineered.columns:\n",
    "    df_engineered['thalach_x_exang'] = df_engineered['thalach'] * df_engineered['exang']\n",
    "    print(\"Added interaction feature: 'thalach_x_exang'\")\n",
    "else:\n",
    "    print(\"Skipping interaction feature 'thalach_x_exang': One or both columns not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299326f6",
   "metadata": {},
   "source": [
    "# --- 3.3. Binning / Discretization ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f66e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a continuous numerical feature into categorical bins\n",
    "if 'age' in df_engineered.columns:\n",
    "    # Define age bins and labels\n",
    "    age_bins = [0, 40, 50, 60, 70, df_engineered['age'].max() + 1]\n",
    "    age_labels = ['<40', '40-49', '50-59', '60-69', '70+']\n",
    "    df_engineered['age_group'] = pd.cut(df_engineered['age'], bins=age_bins, labels=age_labels, right=False)\n",
    "    print(\"Added binned feature: 'age_group'\")\n",
    "    print(\"Distribution of 'age_group':\")\n",
    "    print(df_engineered['age_group'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"Skipping binning for 'age': Column not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3197436e",
   "metadata": {},
   "source": [
    "# --- 3.4. Ratio Features ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad36386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features as ratios of existing numerical features\n",
    "if 'chol' in df_engineered.columns and 'trestbps' in df_engineered.columns:\n",
    "    # Avoid division by zero\n",
    "    df_engineered['chol_to_trestbps_ratio'] = np.where(\n",
    "        df_engineered['trestbps'] != 0,\n",
    "        df_engineered['chol'] / df_engineered['trestbps'],\n",
    "        0 # Or np.nan, depending on how you want to handle zero blood pressure\n",
    "    )\n",
    "    print(\"Added ratio feature: 'chol_to_trestbps_ratio'\")\n",
    "else:\n",
    "    print(\"Skipping ratio feature 'chol_to_trestbps_ratio': One or both columns not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed86aa6",
   "metadata": {},
   "source": [
    "# --- 3.5. Combining One-Hot Encoded 'cp' into a single 'cp_type' categorical feature ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b6933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is useful if you want to treat cp as a single categorical feature again\n",
    "# assuming cp_0, cp_1, cp_2, cp_3 represent different types (e.g., 0, 1, 2, 3)\n",
    "cp_cols = ['cp_0', 'cp_1', 'cp_2', 'cp_3']\n",
    "actual_cp_cols = [col for col in cp_cols if col in df_engineered.columns]\n",
    "\n",
    "if len(actual_cp_cols) == 4: # Ensure all one-hot columns are present\n",
    "    # Find the column with value 1 for each row\n",
    "    df_engineered['cp_type'] = df_engineered[actual_cp_cols].idxmax(axis=1)\n",
    "    # Convert 'cp_type' from 'cp_X' string to integer X\n",
    "    df_engineered['cp_type'] = df_engineered['cp_type'].str.replace('cp_', '').astype(int)\n",
    "    print(\"Combined one-hot encoded 'cp' into 'cp_type' categorical feature.\")\n",
    "    print(\"Distribution of 'cp_type':\")\n",
    "    print(df_engineered['cp_type'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"Skipping 'cp_type' combination: Not all one-hot encoded 'cp' columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de89a91",
   "metadata": {},
   "source": [
    "# --- Final Check and Display ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476eb9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Check and Display ---\n",
    "print(\"\\n--- Advanced Feature Engineering Complete ---\")\n",
    "print(f\"New dataset shape: {df_engineered.shape}\")\n",
    "print(\"\\nFirst 10 rows of the DataFrame with engineered features:\")\n",
    "print(df_engineered.head(10))\n",
    "\n",
    "print(\"\\nNew columns added:\")\n",
    "# Identify new columns by comparing with original columns\n",
    "new_cols = [col for col in df_engineered.columns if col not in df.columns]\n",
    "print(new_cols)\n",
    "\n",
    "print(\"\\nData types of new columns:\")\n",
    "if new_cols:\n",
    "    print(df_engineered[new_cols].dtypes)\n",
    "else:\n",
    "    print(\"No new columns were added.\")\n",
    "# You can now use df_engineered for further modeling or analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit_pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
