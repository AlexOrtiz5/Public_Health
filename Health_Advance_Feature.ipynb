{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6d00114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures # For creating polynomial features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d36bc48",
   "metadata": {},
   "source": [
    "# --- 1. Load the Dataset ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1648549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "      <th>cp_0</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>cp_2</th>\n",
       "      <th>cp_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0     52    1       125   212    0        1      168      0      1.0      2   \n",
       "1     53    1       140   203    1        0      155      1      3.1      0   \n",
       "2     70    1       145   174    0        1      125      1      2.6      0   \n",
       "3     61    1       148   203    0        1      161      0      0.0      2   \n",
       "4     62    0       138   294    1        1      106      0      1.9      1   \n",
       "..   ...  ...       ...   ...  ...      ...      ...    ...      ...    ...   \n",
       "297   68    0       120   211    0        0      115      0      1.5      1   \n",
       "298   44    0       108   141    0        1      175      0      0.6      1   \n",
       "299   52    1       128   255    0        1      161      1      0.0      2   \n",
       "300   59    1       160   273    0        0      125      0      0.0      2   \n",
       "301   54    1       120   188    0        1      113      0      1.4      1   \n",
       "\n",
       "     ca  thal  target  cp_0  cp_1  cp_2  cp_3  \n",
       "0     2     3       0     1     0     0     0  \n",
       "1     0     3       0     1     0     0     0  \n",
       "2     0     3       0     1     0     0     0  \n",
       "3     1     3       0     1     0     0     0  \n",
       "4     3     2       0     1     0     0     0  \n",
       "..   ..   ...     ...   ...   ...   ...   ...  \n",
       "297   0     2       1     0     0     1     0  \n",
       "298   0     2       1     0     0     1     0  \n",
       "299   1     3       0     1     0     0     0  \n",
       "300   0     2       0     0     0     0     1  \n",
       "301   1     3       0     1     0     0     0  \n",
       "\n",
       "[302 rows x 17 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data that is inside of the CSV\n",
    "df = pd.read_csv(\"./Health_Data/cleaned_health.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "929eb18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define original features and target columns\n",
    "ORIGINAL_FEATURES = [\n",
    "    'age', 'sex', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
    "    'exang', 'oldpeak', 'slope', 'ca', 'thal',\n",
    "    'cp_0', 'cp_1', 'cp_2', 'cp_3'\n",
    "]\n",
    "TARGET_COL = 'target' # The column indicating disease presence (0 or 1)\n",
    "\n",
    "# Define numerical columns for imputation and potential engineering\n",
    "NUMERICAL_COLS_FOR_PROCESSING = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a47d2b",
   "metadata": {},
   "source": [
    "# --- 2. Data Preprocessing (Ensuring Cleanliness and Correct Types) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abb0d8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Preprocessing for Feature Engineering ---\n",
      "Missing values before imputation:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Missing values after imputation:\n",
      "age         0\n",
      "sex         0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "cp_0        0\n",
      "cp_1        0\n",
      "cp_2        0\n",
      "cp_3        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Data Preprocessing for Feature Engineering ---\")\n",
    "\n",
    "# Handle '?' or other non-numeric values if they exist, converting to NaN first\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.replace('N/A', np.nan, inplace=True)\n",
    "\n",
    "# Convert all relevant columns to numeric, coercing errors\n",
    "all_relevant_cols = ORIGINAL_FEATURES + [TARGET_COL]\n",
    "for col in all_relevant_cols:\n",
    "    if col in df.columns:\n",
    "        if col in NUMERICAL_COLS_FOR_PROCESSING:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        else: # Categorical/binary features including target\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64') # Use nullable integer\n",
    "\n",
    "# Impute missing values after type conversion\n",
    "print(\"Missing values before imputation:\")\n",
    "print(df[all_relevant_cols].isnull().sum()[df[all_relevant_cols].isnull().sum() > 0])\n",
    "\n",
    "for col in all_relevant_cols:\n",
    "    if col in df.columns and df[col].isnull().any():\n",
    "        if col in NUMERICAL_COLS_FOR_PROCESSING:\n",
    "            median_val = df[col].median()\n",
    "            df[col].fillna(median_val, inplace=True)\n",
    "            print(f\"Filled missing values in '{col}' with its median ({median_val}).\")\n",
    "        else: # Categorical/binary features including target\n",
    "            mode_val = df[col].mode()[0]\n",
    "            df[col].fillna(mode_val, inplace=True)\n",
    "            print(f\"Filled missing values in '{col}' with its mode ({mode_val}).\")\n",
    "\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(df[all_relevant_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de13704",
   "metadata": {},
   "source": [
    "# --- 3. Advanced Feature Engineering ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dbbf103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing Advanced Feature Engineering ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Performing Advanced Feature Engineering ---\")\n",
    "\n",
    "# Create a copy of the DataFrame to add new features\n",
    "df_engineered = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae8a17",
   "metadata": {},
   "source": [
    "# --- 3.1. Polynomial Features ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fd6d402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added polynomial features for: ['age', 'trestbps', 'chol']\n",
      "New polynomial features created: ['age^2', 'age trestbps', 'age chol', 'trestbps^2', 'trestbps chol', 'chol^2']\n"
     ]
    }
   ],
   "source": [
    "# Create polynomial features for selected numerical columns\n",
    "# degree=2 means it will create feature^2 and interaction terms (feature1 * feature2)\n",
    "# include_bias=False ensures it doesn't add a column of all ones\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "cols_for_poly = ['age', 'trestbps', 'chol'] # Select features to create polynomials from\n",
    "\n",
    "# Ensure selected columns exist before processing\n",
    "actual_cols_for_poly = [col for col in cols_for_poly if col in df_engineered.columns]\n",
    "\n",
    "if actual_cols_for_poly:\n",
    "    # Fit and transform the selected columns\n",
    "    poly_features = poly.fit_transform(df_engineered[actual_cols_for_poly])\n",
    "    # Get the names of the new polynomial features\n",
    "    poly_feature_names = poly.get_feature_names_out(actual_cols_for_poly)\n",
    "    # Create a DataFrame for the new polynomial features\n",
    "    poly_df = pd.DataFrame(poly_features, columns=poly_feature_names, index=df_engineered.index)\n",
    "\n",
    "    # --- CRITICAL FIX: Drop the original columns from poly_df before concatenating ---\n",
    "    # PolynomialFeatures with include_bias=False still outputs original features.\n",
    "    # We only want the *new* polynomial and interaction terms.\n",
    "    cols_to_drop_from_poly_df = [col for col in actual_cols_for_poly if col in poly_df.columns]\n",
    "    poly_df = poly_df.drop(columns=cols_to_drop_from_poly_df, errors='ignore')\n",
    "\n",
    "    # Concatenate only the *new* polynomial features to the main DataFrame\n",
    "    df_engineered = pd.concat([df_engineered, poly_df], axis=1)\n",
    "    print(f\"Added polynomial features for: {actual_cols_for_poly}\")\n",
    "    print(f\"New polynomial features created: {poly_df.columns.tolist()}\") # Print actual new columns\n",
    "else:\n",
    "    print(\"Skipping polynomial features: None of the specified columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37478250",
   "metadata": {},
   "source": [
    "# --- 3.2. Interaction Features (Manual) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24daa351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added interaction feature: 'age_x_chol'\n",
      "Added interaction feature: 'thalach_x_exang'\n"
     ]
    }
   ],
   "source": [
    "# Create specific interaction terms that might be clinically relevant\n",
    "# Ensure both interacting columns exist\n",
    "if 'age' in df_engineered.columns and 'chol' in df_engineered.columns:\n",
    "    # Applying .squeeze() to ensure the result is a Series, even if it's a 1-column DataFrame\n",
    "    df_engineered['age_x_chol'] = (df_engineered['age'] * df_engineered['chol']).squeeze()\n",
    "    print(\"Added interaction feature: 'age_x_chol'\")\n",
    "else:\n",
    "    print(\"Skipping interaction feature 'age_x_chol': One or both columns not found.\")\n",
    "\n",
    "if 'thalach' in df_engineered.columns and 'exang' in df_engineered.columns:\n",
    "    # Applying .squeeze() for consistency\n",
    "    df_engineered['thalach_x_exang'] = (df_engineered['thalach'] * df_engineered['exang']).squeeze()\n",
    "    print(\"Added interaction feature: 'thalach_x_exang'\")\n",
    "else:\n",
    "    print(\"Skipping interaction feature 'thalach_x_exang': One or both columns not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299326f6",
   "metadata": {},
   "source": [
    "# --- 3.3. Binning / Discretization ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c9f66e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added binned feature: 'age_group'\n",
      "Distribution of 'age_group':\n",
      "<40       15\n",
      "40-49     72\n",
      "50-59    125\n",
      "60-69     80\n",
      "70+       10\n",
      "Name: age_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert a continuous numerical feature into categorical bins\n",
    "if 'age' in df_engineered.columns:\n",
    "    # Define age bins and labels\n",
    "    age_bins = [0, 40, 50, 60, 70, df_engineered['age'].max() + 1]\n",
    "    age_labels = ['<40', '40-49', '50-59', '60-69', '70+']\n",
    "    df_engineered['age_group'] = pd.cut(df_engineered['age'], bins=age_bins, labels=age_labels, right=False)\n",
    "    print(\"Added binned feature: 'age_group'\")\n",
    "    print(\"Distribution of 'age_group':\")\n",
    "    print(df_engineered['age_group'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"Skipping binning for 'age': Column not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3197436e",
   "metadata": {},
   "source": [
    "# --- 3.4. Ratio Features ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad36386b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added ratio feature: 'chol_to_trestbps_ratio'\n"
     ]
    }
   ],
   "source": [
    "# Create new features as ratios of existing numerical features\n",
    "if 'chol' in df_engineered.columns and 'trestbps' in df_engineered.columns:\n",
    "    # Avoid division by zero\n",
    "    df_engineered['chol_to_trestbps_ratio'] = np.where(\n",
    "        df_engineered['trestbps'] != 0,\n",
    "        df_engineered['chol'] / df_engineered['trestbps'],\n",
    "        0 # Or np.nan, depending on how you want to handle zero blood pressure\n",
    "    )\n",
    "    print(\"Added ratio feature: 'chol_to_trestbps_ratio'\")\n",
    "else:\n",
    "    print(\"Skipping ratio feature 'chol_to_trestbps_ratio': One or both columns not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed86aa6",
   "metadata": {},
   "source": [
    "# --- 3.5. Combining One-Hot Encoded 'cp' into a single 'cp_type' categorical feature ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7b6933e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined one-hot encoded 'cp' into 'cp_type' categorical feature.\n",
      "Distribution of 'cp_type':\n",
      "0    143\n",
      "1     50\n",
      "2     86\n",
      "3     23\n",
      "Name: cp_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# This is useful if you want to treat cp as a single categorical feature again\n",
    "# assuming cp_0, cp_1, cp_2, cp_3 represent different types (e.g., 0, 1, 2, 3)\n",
    "cp_cols = ['cp_0', 'cp_1', 'cp_2', 'cp_3']\n",
    "actual_cp_cols = [col for col in cp_cols if col in df_engineered.columns]\n",
    "\n",
    "if len(actual_cp_cols) == 4: # Ensure all one-hot columns are present\n",
    "    # Find the column with value 1 for each row\n",
    "    df_engineered['cp_type'] = df_engineered[actual_cp_cols].idxmax(axis=1)\n",
    "    # Convert 'cp_type' from 'cp_X' string to integer X\n",
    "    df_engineered['cp_type'] = df_engineered['cp_type'].str.replace('cp_', '').astype(int)\n",
    "    print(\"Combined one-hot encoded 'cp' into 'cp_type' categorical feature.\")\n",
    "    print(\"Distribution of 'cp_type':\")\n",
    "    print(df_engineered['cp_type'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"Skipping 'cp_type' combination: Not all one-hot encoded 'cp' columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de89a91",
   "metadata": {},
   "source": [
    "# --- Final Check and Display ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "476eb9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Advanced Feature Engineering Complete ---\n",
      "New dataset shape: (302, 28)\n",
      "\n",
      "First 10 rows of the DataFrame with engineered features:\n",
      "   age  sex  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   52    1       125   212    0        1      168      0      1.0      2   \n",
      "1   53    1       140   203    1        0      155      1      3.1      0   \n",
      "2   70    1       145   174    0        1      125      1      2.6      0   \n",
      "3   61    1       148   203    0        1      161      0      0.0      2   \n",
      "4   62    0       138   294    1        1      106      0      1.9      1   \n",
      "5   58    0       100   248    0        0      122      0      1.0      1   \n",
      "6   58    1       114   318    0        2      140      0      4.4      0   \n",
      "7   55    1       160   289    0        0      145      1      0.8      1   \n",
      "8   46    1       120   249    0        0      144      0      0.8      2   \n",
      "9   54    1       122   286    0        0      116      1      3.2      1   \n",
      "\n",
      "   ...  age trestbps  age chol  trestbps^2  trestbps chol    chol^2  \\\n",
      "0  ...        6500.0   11024.0     15625.0        26500.0   44944.0   \n",
      "1  ...        7420.0   10759.0     19600.0        28420.0   41209.0   \n",
      "2  ...       10150.0   12180.0     21025.0        25230.0   30276.0   \n",
      "3  ...        9028.0   12383.0     21904.0        30044.0   41209.0   \n",
      "4  ...        8556.0   18228.0     19044.0        40572.0   86436.0   \n",
      "5  ...        5800.0   14384.0     10000.0        24800.0   61504.0   \n",
      "6  ...        6612.0   18444.0     12996.0        36252.0  101124.0   \n",
      "7  ...        8800.0   15895.0     25600.0        46240.0   83521.0   \n",
      "8  ...        5520.0   11454.0     14400.0        29880.0   62001.0   \n",
      "9  ...        6588.0   15444.0     14884.0        34892.0   81796.0   \n",
      "\n",
      "   age_x_chol  thalach_x_exang  age_group  chol_to_trestbps_ratio  cp_type  \n",
      "0       11024                0      50-59                1.696000        0  \n",
      "1       10759              155      50-59                1.450000        0  \n",
      "2       12180              125        70+                1.200000        0  \n",
      "3       12383                0      60-69                1.371622        0  \n",
      "4       18228                0      60-69                2.130435        0  \n",
      "5       14384                0      50-59                2.480000        0  \n",
      "6       18444                0      50-59                2.789474        0  \n",
      "7       15895              145      50-59                1.806250        0  \n",
      "8       11454                0      40-49                2.075000        0  \n",
      "9       15444              116      50-59                2.344262        0  \n",
      "\n",
      "[10 rows x 28 columns]\n",
      "\n",
      "New columns added:\n",
      "['age^2', 'age trestbps', 'age chol', 'trestbps^2', 'trestbps chol', 'chol^2', 'age_x_chol', 'thalach_x_exang', 'age_group', 'chol_to_trestbps_ratio', 'cp_type']\n",
      "\n",
      "Data types of new columns:\n",
      "age^2                      float64\n",
      "age trestbps               float64\n",
      "age chol                   float64\n",
      "trestbps^2                 float64\n",
      "trestbps chol              float64\n",
      "chol^2                     float64\n",
      "age_x_chol                   int64\n",
      "thalach_x_exang              Int64\n",
      "age_group                 category\n",
      "chol_to_trestbps_ratio     float64\n",
      "cp_type                      int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- Final Check and Display ---\n",
    "print(\"\\n--- Advanced Feature Engineering Complete ---\")\n",
    "print(f\"New dataset shape: {df_engineered.shape}\")\n",
    "print(\"\\nFirst 10 rows of the DataFrame with engineered features:\")\n",
    "print(df_engineered.head(10))\n",
    "\n",
    "print(\"\\nNew columns added:\")\n",
    "# Identify new columns by comparing with original columns\n",
    "new_cols = [col for col in df_engineered.columns if col not in df.columns]\n",
    "print(new_cols)\n",
    "\n",
    "print(\"\\nData types of new columns:\")\n",
    "if new_cols:\n",
    "    print(df_engineered[new_cols].dtypes)\n",
    "else:\n",
    "    print(\"No new columns were added.\")\n",
    "# You can now use df_engineered for further modeling or analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit_pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
