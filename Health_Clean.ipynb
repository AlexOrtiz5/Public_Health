{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed89abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962c945",
   "metadata": {},
   "source": [
    "# --- 1. Load the Dataset ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51a50746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0      52    1   0       125   212    0        1      168      0      1.0   \n",
       "1      53    1   0       140   203    1        0      155      1      3.1   \n",
       "2      70    1   0       145   174    0        1      125      1      2.6   \n",
       "3      61    1   0       148   203    0        1      161      0      0.0   \n",
       "4      62    0   0       138   294    1        1      106      0      1.9   \n",
       "...   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "1020   59    1   1       140   221    0        1      164      1      0.0   \n",
       "1021   60    1   0       125   258    0        0      141      1      2.8   \n",
       "1022   47    1   0       110   275    0        0      118      1      1.0   \n",
       "1023   50    0   0       110   254    0        0      159      0      0.0   \n",
       "1024   54    1   0       120   188    0        1      113      0      1.4   \n",
       "\n",
       "      slope  ca  thal  target  \n",
       "0         2   2     3       0  \n",
       "1         0   0     3       0  \n",
       "2         0   0     3       0  \n",
       "3         2   1     3       0  \n",
       "4         1   3     2       0  \n",
       "...     ...  ..   ...     ...  \n",
       "1020      2   0     2       1  \n",
       "1021      1   1     3       0  \n",
       "1022      1   1     2       0  \n",
       "1023      2   0     2       1  \n",
       "1024      1   1     3       0  \n",
       "\n",
       "[1025 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data that is inside of the CSV\n",
    "df = pd.read_csv(\"./Health_Data/heart.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29e1d1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
       "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b2685ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the expected columns. This helps in verifying the data.\n",
    "EXPECTED_COLUMNS = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
    "    'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890fc5b8",
   "metadata": {},
   "source": [
    "# --- 2. Verify Columns ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25083f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All expected columns are present.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Verify Columns ---\n",
    "# Check if all expected columns are present\n",
    "missing_cols = [col for col in EXPECTED_COLUMNS if col not in df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"\\nWarning: The following expected columns are missing from the dataset: {missing_cols}\")\n",
    "    # You might want to handle this, e.g., by exiting or creating placeholder columns\n",
    "    # For now, we'll proceed with the available columns.\n",
    "else:\n",
    "    print(\"\\nAll expected columns are present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbec471",
   "metadata": {},
   "source": [
    "# --- 3. Handle Missing Values ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85fa037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Handling Missing Values ---\n",
      "Checking for missing values (NaNs):\n",
      "Series([], dtype: int64)\n",
      "No missing values found in the dataset.\n",
      "\n",
      "Missing values after imputation:\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Handling Missing Values ---\")\n",
    "print(\"Checking for missing values (NaNs):\")\n",
    "missing_values_summary = df.isnull().sum()\n",
    "print(missing_values_summary[missing_values_summary > 0])\n",
    "\n",
    "if missing_values_summary.sum() == 0:\n",
    "    print(\"No missing values found in the dataset.\")\n",
    "else:\n",
    "    print(\"\\nMissing values detected. Here are some common strategies:\")\n",
    "    # Strategy 1: Drop rows with any missing values (use with caution, can lose a lot of data)\n",
    "    # df_cleaned = df.dropna()\n",
    "    # print(f\"Shape after dropping rows with NaNs: {df_cleaned.shape}\")\n",
    "\n",
    "    # Strategy 2: Impute missing numerical values (e.g., with mean, median, or mode)\n",
    "    # For 'age', 'trestbps', 'chol', 'thalach', 'oldpeak' (assuming these are numerical)\n",
    "    numerical_cols_to_impute = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "    for col in numerical_cols_to_impute:\n",
    "        if col in df.columns and df[col].isnull().any():\n",
    "            median_val = df[col].median()\n",
    "            df[col].fillna(median_val, inplace=True)\n",
    "            print(f\"Filled missing values in '{col}' with its median ({median_val}).\")\n",
    "\n",
    "    # Strategy 3: Impute missing categorical values (e.g., with mode)\n",
    "    # For 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal', 'target' (assuming these are categorical/ordinal)\n",
    "    # Note: 'ca' and 'thal' might have '?' or other non-numeric values representing missing data\n",
    "    # Before imputation, convert non-numeric missing indicators to NaN\n",
    "    df.replace('?', np.nan, inplace=True) # Replace '?' with NaN\n",
    "    df.replace('N/A', np.nan, inplace=True) # Replace 'N/A' with NaN (add other common indicators if needed)\n",
    "\n",
    "    categorical_cols_to_impute = ['cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal', 'sex']\n",
    "    for col in categorical_cols_to_impute:\n",
    "        if col in df.columns and df[col].isnull().any():\n",
    "            # Convert to numeric if possible before finding mode, as mode works better on numerical data\n",
    "            # Or treat them as strings if they are truly categorical and not ordinal\n",
    "            try:\n",
    "                # Attempt to convert to numeric, coercing errors to NaN\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                mode_val = df[col].mode()[0] # mode() returns a Series, take the first element\n",
    "                df[col].fillna(mode_val, inplace=True)\n",
    "                print(f\"Filled missing values in '{col}' with its mode ({mode_val}).\")\n",
    "            except Exception:\n",
    "                # If conversion fails, treat as string and impute with string mode\n",
    "                mode_val_str = df[col].astype(str).mode()[0]\n",
    "                df[col].fillna(mode_val_str, inplace=True)\n",
    "                print(f\"Filled missing string values in '{col}' with its mode ({mode_val_str}).\")\n",
    "\n",
    "\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c01750",
   "metadata": {},
   "source": [
    "# --- 4. Handle Duplicate Rows ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf446b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Handling Duplicate Rows ---\n",
      "Removed 723 duplicate rows.\n",
      "Shape after removing duplicates: (302, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Handling Duplicate Rows ---\")\n",
    "initial_rows = df.shape[0]\n",
    "df.drop_duplicates(inplace=True)\n",
    "duplicates_removed = initial_rows - df.shape[0]\n",
    "if duplicates_removed > 0:\n",
    "    print(f\"Removed {duplicates_removed} duplicate rows.\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")\n",
    "print(f\"Shape after removing duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e0406",
   "metadata": {},
   "source": [
    "# --- 5. Check and Correct Data Types ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b017597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking Data Types ---\n",
      "Current data types:\n",
      "age           int64\n",
      "sex           int64\n",
      "cp            int64\n",
      "trestbps      int64\n",
      "chol          int64\n",
      "fbs           int64\n",
      "restecg       int64\n",
      "thalach       int64\n",
      "exang         int64\n",
      "oldpeak     float64\n",
      "slope         int64\n",
      "ca            int64\n",
      "thal          int64\n",
      "target        int64\n",
      "dtype: object\n",
      "Converted 'age' to int.\n",
      "Converted 'sex' to int.\n",
      "Converted 'cp' to int.\n",
      "Converted 'trestbps' to int.\n",
      "Converted 'chol' to int.\n",
      "Converted 'fbs' to int.\n",
      "Converted 'restecg' to int.\n",
      "Converted 'thalach' to int.\n",
      "Converted 'exang' to int.\n",
      "Converted 'oldpeak' to float.\n",
      "Converted 'slope' to int.\n",
      "Converted 'ca' to int.\n",
      "Converted 'thal' to int.\n",
      "Converted 'target' to int.\n",
      "\n",
      "Missing values after type coercion (if any):\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Data types after correction:\n",
      "age           Int64\n",
      "sex           Int64\n",
      "cp            Int64\n",
      "trestbps      Int64\n",
      "chol          Int64\n",
      "fbs           Int64\n",
      "restecg       Int64\n",
      "thalach       Int64\n",
      "exang         Int64\n",
      "oldpeak     float64\n",
      "slope         Int64\n",
      "ca            Int64\n",
      "thal          Int64\n",
      "target        Int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Checking Data Types ---\")\n",
    "print(\"Current data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Define expected data types for better consistency\n",
    "# Adjust these based on your understanding of the dataset\n",
    "expected_data_types = {\n",
    "    'age': 'int',\n",
    "    'sex': 'int', # Assuming 0/1 for male/female\n",
    "    'cp': 'int', # Chest Pain Type (ordinal/categorical)\n",
    "    'trestbps': 'int', # Resting Blood Pressure\n",
    "    'chol': 'int', # Serum Cholestoral\n",
    "    'fbs': 'int', # Fasting Blood Sugar (> 120 mg/dl)\n",
    "    'restecg': 'int', # Resting Electrocardiographic Results\n",
    "    'thalach': 'int', # Maximum Heart Rate Achieved\n",
    "    'exang': 'int', # Exercise Induced Angina\n",
    "    'oldpeak': 'float', # ST depression induced by exercise relative to rest\n",
    "    'slope': 'int', # The slope of the peak exercise ST segment\n",
    "    'ca': 'int', # Number of major vessels (0-3) colored by flourosopy\n",
    "    'thal': 'int', # Thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n",
    "    'target': 'int' # Target variable (0 = no disease, 1 = disease)\n",
    "}\n",
    "\n",
    "for col, dtype in expected_data_types.items():\n",
    "    if col in df.columns:\n",
    "        try:\n",
    "            # Use errors='coerce' to turn unparseable values into NaN\n",
    "            # This is important if some non-numeric values slipped through\n",
    "            if dtype == 'int':\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64') # Use Int64 for nullable integer\n",
    "            elif dtype == 'float':\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce').astype('float')\n",
    "            # Add more type conversions if needed (e.g., 'category', 'bool')\n",
    "            print(f\"Converted '{col}' to {dtype}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not convert '{col}' to {dtype}: {e}\")\n",
    "\n",
    "# Re-check for NaNs introduced by type coercion\n",
    "print(\"\\nMissing values after type coercion (if any):\")\n",
    "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "\n",
    "# Handle any new NaNs introduced by coercion (e.g., impute again or drop)\n",
    "# For simplicity, we'll impute with mode/median again for newly introduced NaNs\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().any():\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            median_val = df[col].median()\n",
    "            df[col].fillna(median_val, inplace=True)\n",
    "            print(f\"Filled new NaNs in '{col}' with median ({median_val}) after coercion.\")\n",
    "        else:\n",
    "            mode_val = df[col].mode()[0]\n",
    "            df[col].fillna(mode_val, inplace=True)\n",
    "            print(f\"Filled new NaNs in '{col}' with mode ({mode_val}) after coercion.\")\n",
    "\n",
    "\n",
    "print(\"\\nData types after correction:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fbba32",
   "metadata": {},
   "source": [
    "# --- 6. Outlier Detection (Basic Example) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2b43411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Basic Outlier Detection ---\n",
      "No significant outliers detected in 'age' using IQR method.\n",
      "Potential outliers detected in 'trestbps': 9 rows.\n",
      "Potential outliers detected in 'chol': 5 rows.\n",
      "Potential outliers detected in 'thalach': 1 rows.\n",
      "Potential outliers detected in 'oldpeak': 5 rows.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Basic Outlier Detection ---\")\n",
    "# For numerical columns, you can use IQR (Interquartile Range) method\n",
    "numerical_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "for col in numerical_cols:\n",
    "    if col in df.columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        if not outliers.empty:\n",
    "            print(f\"Potential outliers detected in '{col}': {len(outliers)} rows.\")\n",
    "            # print(outliers[[col]]) # Uncomment to see the outlier rows\n",
    "            # You might choose to:\n",
    "            # 1. Cap outliers (e.g., replace with bounds)\n",
    "            # df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "            # df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "            # 2. Remove outliers (use with caution)\n",
    "            # df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "        else:\n",
    "            print(f\"No significant outliers detected in '{col}' using IQR method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb24ab34",
   "metadata": {},
   "source": [
    "# --- 7. Categorical Data Encoding (Conceptual) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18a70bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Categorical Data Encoding (Conceptual) ---\n",
      "Applied One-Hot Encoding to 'cp'.\n",
      "Assuming categorical columns are already numerically encoded based on typical public health datasets.\n",
      "If any categorical columns were strings, One-Hot Encoding or Label Encoding would be applied here.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Categorical Data Encoding (Conceptual) ---\")\n",
    "# The columns 'sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal', 'target'\n",
    "# are likely already encoded as numerical (0/1 or other integer categories).\n",
    "# If they were strings (e.g., 'Male', 'Female'), you would need to encode them.\n",
    "\n",
    "# Example if 'sex' was 'Male'/'Female':\n",
    "if 'sex' in df.columns and df['sex'].dtype == 'object': # Check if it's a string/object type\n",
    "    df['sex'] = df['sex'].map({'Female': 0, 'Male': 1})\n",
    "    print(\"Encoded 'sex' column.\")\n",
    "\n",
    "# For multi-category nominal features, use One-Hot Encoding:\n",
    "# Example: If 'cp' was 'typical angina', 'atypical angina', etc.\n",
    "df = pd.get_dummies(df, columns=['cp'], prefix='cp')\n",
    "print(\"Applied One-Hot Encoding to 'cp'.\")\n",
    "\n",
    "print(\"Assuming categorical columns are already numerically encoded based on typical public health datasets.\")\n",
    "print(\"If any categorical columns were strings, One-Hot Encoding or Label Encoding would be applied here.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dab3e1",
   "metadata": {},
   "source": [
    "# --- Final Summary ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c8e4fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Cleaning Complete ---\n",
      "Final dataset shape: (302, 17)\n",
      "\n",
      "Final data types:\n",
      "age           Int64\n",
      "sex           Int64\n",
      "trestbps      Int64\n",
      "chol          Int64\n",
      "fbs           Int64\n",
      "restecg       Int64\n",
      "thalach       Int64\n",
      "exang         Int64\n",
      "oldpeak     float64\n",
      "slope         Int64\n",
      "ca            Int64\n",
      "thal          Int64\n",
      "target        Int64\n",
      "cp_0          uint8\n",
      "cp_1          uint8\n",
      "cp_2          uint8\n",
      "cp_3          uint8\n",
      "dtype: object\n",
      "\n",
      "Final missing values check:\n",
      "age         0\n",
      "sex         0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "cp_0        0\n",
      "cp_1        0\n",
      "cp_2        0\n",
      "cp_3        0\n",
      "dtype: int64\n",
      "\n",
      "Cleaned data head:\n",
      "   age  sex  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  ca  \\\n",
      "0   52    1       125   212    0        1      168      0      1.0      2   2   \n",
      "1   53    1       140   203    1        0      155      1      3.1      0   0   \n",
      "2   70    1       145   174    0        1      125      1      2.6      0   0   \n",
      "3   61    1       148   203    0        1      161      0      0.0      2   1   \n",
      "4   62    0       138   294    1        1      106      0      1.9      1   3   \n",
      "\n",
      "   thal  target  cp_0  cp_1  cp_2  cp_3  \n",
      "0     3       0     1     0     0     0  \n",
      "1     3       0     1     0     0     0  \n",
      "2     3       0     1     0     0     0  \n",
      "3     3       0     1     0     0     0  \n",
      "4     2       0     1     0     0     0  \n"
     ]
    }
   ],
   "source": [
    "# --- Final Summary ---\n",
    "print(\"\\n--- Data Cleaning Complete ---\")\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "print(\"\\nFinal data types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nFinal missing values check:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nCleaned data head:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8b1bb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "      <th>cp_0</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>cp_2</th>\n",
       "      <th>cp_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0     52    1       125   212    0        1      168      0      1.0      2   \n",
       "1     53    1       140   203    1        0      155      1      3.1      0   \n",
       "2     70    1       145   174    0        1      125      1      2.6      0   \n",
       "3     61    1       148   203    0        1      161      0      0.0      2   \n",
       "4     62    0       138   294    1        1      106      0      1.9      1   \n",
       "..   ...  ...       ...   ...  ...      ...      ...    ...      ...    ...   \n",
       "723   68    0       120   211    0        0      115      0      1.5      1   \n",
       "733   44    0       108   141    0        1      175      0      0.6      1   \n",
       "739   52    1       128   255    0        1      161      1      0.0      2   \n",
       "843   59    1       160   273    0        0      125      0      0.0      2   \n",
       "878   54    1       120   188    0        1      113      0      1.4      1   \n",
       "\n",
       "     ca  thal  target  cp_0  cp_1  cp_2  cp_3  \n",
       "0     2     3       0     1     0     0     0  \n",
       "1     0     3       0     1     0     0     0  \n",
       "2     0     3       0     1     0     0     0  \n",
       "3     1     3       0     1     0     0     0  \n",
       "4     3     2       0     1     0     0     0  \n",
       "..   ..   ...     ...   ...   ...   ...   ...  \n",
       "723   0     2       1     0     0     1     0  \n",
       "733   0     2       1     0     0     1     0  \n",
       "739   1     3       0     1     0     0     0  \n",
       "843   0     2       0     0     0     0     1  \n",
       "878   1     3       0     1     0     0     0  \n",
       "\n",
       "[302 rows x 17 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "044a243f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang',\n",
       "       'oldpeak', 'slope', 'ca', 'thal', 'target', 'cp_0', 'cp_1', 'cp_2',\n",
       "       'cp_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "813f49f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save the cleaned data\n",
    "df.to_csv('./Health_Data/cleaned_health.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit_pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
